import logging
import re
import threading
import time
import math
import psutil
import shutil
import signal
import subprocess
import os
import asyncio
import requests
import pathlib
import urllib
import string

from bot.helper.telegram_helper.bot_commands import BotCommands
from bot import dispatcher, download_dict, download_dict_lock, STATUS_LIMIT
from telegram import InlineKeyboardMarkup
from telegram.ext import CallbackQueryHandler
from bot.helper.telegram_helper import button_build, message_utils

LOGGER = logging.getLogger(__name__)

MAGNET_REGEX = r"magnet:\?xt=urn:btih:[a-zA-Z0-9]*"

URL_REGEX = r"(?:(?:https?|ftp):\/\/)?[\w/\-?=%.]+\.[\w/\-?=%.]+"

COUNT = 0
PAGE_NO = 1


class MirrorStatus:
    STATUS_UPLOADING = "âŒˆâ³ â­ â‡…ğš„ğš™ğš•ğš˜ğšŠğšğš’ğš—ğš.....ê˜‰....ğŸ“¤ â« "
    STATUS_DOWNLOADING = "âŒˆâ³ ğŸŒŸ â‡…ğ™³ğš˜ğš ğš—ğš•ğš˜ğšŠğšğš’ğš—ğš.....ê˜‰....ğŸ“¥ â¬ "
    STATUS_CLONING = " ğŸ¤¶ Cloning..!. â™»ï¸ "
    STATUS_WAITING = " ğŸ˜¡ ğš†ğšŠğš’ğšğš’ğš—ğš...ğŸ“ "
    STATUS_FAILED = " ğŸ§ Failed ğŸš«.. Cleaning..ğŸŒ€"
    STATUS_PAUSE = " ğŸ¤·â€â™€ï¸ Paused...â¸ "
    STATUS_ARCHIVING = " ğŸ’ Archiving...ğŸ” "
    STATUS_EXTRACTING = " ğŸ’” Extracting...ğŸ“‚ "
    STATUS_SPLITTING = " ğŸ’ Splitting...âœ‚ï¸ "


PROGRESS_MAX_SIZE = 100 // 8
PROGRESS_INCOMPLETE = ['ğŸ‘‘','ğŸ¯','ğŸŒ»', 'ğŸ’', 'ğŸ‘»', 'ğŸ¥€', 'ğŸ’', 'ğŸŒ¹', 'ğŸ’']

SIZE_UNITS = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']


class setInterval:
    def __init__(self, interval, action):
        self.interval = interval
        self.action = action
        self.stopEvent = threading.Event()
        thread = threading.Thread(target=self.__setInterval)
        thread.start()

    def __setInterval(self):
        nextTime = time.time() + self.interval
        while not self.stopEvent.wait(nextTime - time.time()):
            nextTime += self.interval
            self.action()

    def cancel(self):
        self.stopEvent.set()

def get_readable_file_size(size_in_bytes) -> str:
    if size_in_bytes is None:
        return '0B'
    index = 0
    while size_in_bytes >= 1024:
        size_in_bytes /= 1024
        index += 1
    try:
        return f'{round(size_in_bytes, 2)}{SIZE_UNITS[index]}'
    except IndexError:
        return 'File too large'

def getDownloadByGid(gid):
    with download_dict_lock:
        for dl in download_dict.values():
            status = dl.status()
            if (
                status
                not in [
                    MirrorStatus.STATUS_ARCHIVING,
                    MirrorStatus.STATUS_EXTRACTING,
                    MirrorStatus.STATUS_SPLITTING,
                ]
                and dl.gid() == gid
            ):
                return dl
    return None

def getAllDownload():
    with download_dict_lock:
        for dlDetails in download_dict.values():
            status = dlDetails.status()
            if (
                status
                not in [
                    MirrorStatus.STATUS_ARCHIVING,
                    MirrorStatus.STATUS_EXTRACTING,
                    MirrorStatus.STATUS_SPLITTING,
                    MirrorStatus.STATUS_CLONING,
                    MirrorStatus.STATUS_UPLOADING,
                ]
                and dlDetails
            ):
                return dlDetails
    return None

def get_progress_bar_string(status):
    completed = status.processed_bytes() / 8
    total = status.size_raw() / 8
    p = 0 if total == 0 else round(completed * 100 / total)
    p = min(max(p, 0), 100)
    cFull = p // 8
    cPart = p % 8 - 1
    p_str = 'Ï€^' * cFull
    if cPart >= 0:
        p_str += PROGRESS_INCOMPLETE[cPart]
    p_str += ' ' * (PROGRESS_MAX_SIZE - cFull)
    p_str = f"[{p_str}]"
    return p_str

def get_readable_message():
    with download_dict_lock:
        msg = ""
        start = 0
        if STATUS_LIMIT is not None:
            dick_no = len(download_dict)
            global pages
            pages = math.ceil(dick_no/STATUS_LIMIT)
            if PAGE_NO > pages and pages != 0:
                globals()['COUNT'] -= STATUS_LIMIT
                globals()['PAGE_NO'] -= 1
            start = COUNT
        for index, download in enumerate(list(download_dict.values())[start:], start=1):
            msg += f"<b>âŒˆâ³ ğŸ—ƒ ğ™µğ™¸ğ™»ğ™´ğ™½ğ™°ğ™¼ğ™´ ğŸ’Œ âª¡ã€: </b> <code>{download.name()} ï¿«â™¼</code>"
            msg += f"\n<b>âŒˆâ³ ğŸ”¥â‡† ğš„ğ™¿ğ™³ğ™°ğšƒğ™´ ğ™¸ğ™½ğ™µğ™¾ ğŸ§ âª¡ã€:âŒœâ†¬</b>"
            msg += f"\n<b>{download.status()}</b>"
            if download.status() not in [
                MirrorStatus.STATUS_ARCHIVING,
                MirrorStatus.STATUS_EXTRACTING,
                MirrorStatus.STATUS_SPLITTING,
            ]:
                msg += f"\n<code>{get_progress_bar_string(download)} {download.progress()}</code>"
                if download.status() == MirrorStatus.STATUS_CLONING:
                    msg += f"\n<b>áŸáÏ´Îá¬á  :</b> <code>{get_readable_file_size(download.processed_bytes())}</code> of <code>{download.size()}</code>\n<b>âŒˆâ³ğŸ’§ ğ™¼ğ™¸ğšğšğ™¾ğš ğ™²ğ™»ğ™¸ğ™´ğ™½ğšƒ : </b> <code>AutoRclone â‰</code>"
                elif download.status() == MirrorStatus.STATUS_UPLOADING:
                    msg += f"\n<b>âŒˆâ³ ğŸ‘° ğš„ğš™ğš•ğš˜ğšŠğšğšğš... ğŸ’ƒ=> </b> <code>{get_readable_file_size(download.processed_bytes())}</code> of <code>{download.size()}ï¸ï¸ï¸ï¸</code>"
                else:
                    msg += f"\n<b>âŒˆâ³ ğŸ‘° ğ™³ğ™¾ğš†ğ™½ğ™»ğ™¾ğ™°ğ™³ ğŸ’ƒ |</b> <code>{get_readable_file_size(download.processed_bytes())}</code> of <code>{download.size()}</code>"
                msg += f"\n<b>âŒˆâ³ ğŸ“¯ ğš‚ğ™¿ğ™´ğ™´ğ™³ âš¡ âª¡ã€:</b> <code>{download.speed()} â‡µ</code>"

                msg += f"\n<b>âŒˆâ³ ğŸ•° ğ™´ğš‚ğšƒğ™¸ğ™¼ğ™°ğšƒğ™´ğ™³ ğšƒğ™¸ğ™¼ğ™´ â³ : </b> <code>{download.eta()}âŒ›</code>"
                msg += f"\n<b>âŒˆâ³ ğŸ˜ ğ™³ğš˜ğš ğš—ğš•ğš˜ğšŠğšğšğš› | </b> <b>{download.message.from_user.first_name}</b>\n<b>âŒˆâ³ âš ï¸ USER - ID âª¡ã€ğŸ‘‰ </b><code>/warn {download.message.from_user.id}</code>"

                try:
                    msg += f"\n<b>âŒˆâ³ğŸ“¡ ğšƒğ™¾ğšğšğ™´ğ™½ğšƒ ğ™¸ğ™½ğ™µğ™¾ âš“ï¸ â‡’\nâŒˆâ³ ğš‚ğ™´ğ™´ğ™³ğ™´ğšğš‚ ğŸŒ¹: </b> <code>{download.aria_download().num_seeders}</code>" \
                           f" | <b> ğ™¿ğ™´ğ™´ğšğš‚ ğŸ¥€ : </b> <code>{download.aria_download().connections}</code>\n<b>âŒˆâ³ ğŸ’ ğ™¼ğ™¸ğšğšğ™¾ğš ğ™²ğ™»ğ™¸ğ™´ğ™½ğšƒ |</b> aria2c â—·"
                except:
                    pass
                try:
                    msg += f"\n<b>âŒˆâ³ ğŸ¤‘ ğš‚ğ™´ğ™´ğ™³ğ™´ğšğš‚ : </b> <code>{download.torrent_info().num_seeds}â˜†</code>" \
                           f"<b>| ğ™»ğ™´ğ™´ğ™²ğ™·ğ™´ğšğš‚ :</b> <code>{download.torrent_info().num_leechs}ğŸ©¸</code>\n<b>âŒˆâ³ ğŸ’ ğšƒğ™¾ğšğšğ™´ğ™½ğšƒ ğ™²ğ™»ğ™¸ğ™´ğ™½ğšƒ | </b> qBittorrent Â¶"
                except:
                    pass
                msg += f"\n<b>âŒˆâ³ ğŸ¤·â€â™€ï¸ ğšƒğ™¾ ğ™²ğ™°ğ™½ğ™²ğ™´ğ™» ğ™³ğ™¾ğš†ğ™½ğ™»ğ™¾ğ™°ğ™³ ğŸ¤¦â€â™€ï¸ |</b> \n<b>=> ğšƒğ™¾ğ™ºğ™´ğ™½ </b> <code>/{BotCommands.CancelMirror} {download.gid()}</code>"
                msg += f"\n<b> â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” </b>"
               
                
                
                
            msg += "\n\n"
            if STATUS_LIMIT is not None and index == STATUS_LIMIT:
                break
        if STATUS_LIMIT is not None and dick_no > STATUS_LIMIT:
            msg += f"<b>âŒˆâ³ â¸ ğ™¿ğ™°ğ™¶ğ™´  : </b> <code>{PAGE_NO}</code> of <code>{pages}</code> | <b>Tasks ğŸ€ :</b> <code>{dick_no}</code>\n"
            buttons = button_build.ButtonMaker()
            buttons.sbutton("=> ÏÑÑ”Î½Î¹Î¿Ï…Ñ• â© ", "pre")
            buttons.sbutton("=> Õ²Ò½xÔµ â© ", "nex")
            
            button = InlineKeyboardMarkup(buttons.build_menu(2))
            return msg, button
        return msg, ""

def flip(update, context):
    query = update.callback_query
    query.answer()
    global COUNT, PAGE_NO
    if query.data == "nex":
        if PAGE_NO == pages:
            COUNT = 0
            PAGE_NO = 1
        else:
            COUNT += STATUS_LIMIT
            PAGE_NO += 1
    elif query.data == "pre":
        if PAGE_NO == 1:
            COUNT = STATUS_LIMIT * (pages - 1)
            PAGE_NO = pages
        else:
            COUNT -= STATUS_LIMIT
            PAGE_NO -= 1
    message_utils.update_all_messages()

def check_limit(size, limit, tar_unzip_limit=None, is_tar_ext=False):
    LOGGER.info('ğŸ¥±Checking File Size...ğŸ§')
    if is_tar_ext and tar_unzip_limit is not None:
        limit = tar_unzip_limit
    if limit is not None:
        limit = limit.split(' ', maxsplit=1)
        limitint = int(limit[0])
        if 'G' in limit[1] or 'g' in limit[1]:
            if size > limitint * 1024**3:
                return True
        elif 'T' in limit[1] or 't' in limit[1]:
            if size > limitint * 1024**4:
                return True

def get_readable_time(seconds: int) -> str:
    result = ''
    (days, remainder) = divmod(seconds, 86400)
    days = int(days)
    if days != 0:
        result += f'{days}d'
    (hours, remainder) = divmod(remainder, 3600)
    hours = int(hours)
    if hours != 0:
        result += f'{hours}h'
    (minutes, seconds) = divmod(remainder, 60)
    minutes = int(minutes)
    if minutes != 0:
        result += f'{minutes}m'
    seconds = int(seconds)
    result += f'{seconds}s'
    return result

def is_url(url: str):
    url = re.findall(URL_REGEX, url)
    return bool(url)

def is_gdrive_link(url: str):
    return "drive.google.com" in url

def is_mega_link(url: str):
    return "mega.nz" in url or "mega.co.nz" in url

def get_mega_link_type(url: str):
    if "folder" in url:
        return "folder"
    elif "file" in url:
        return "file"
    elif "/#F!" in url:
        return "folder"
    return "file"

def is_magnet(url: str):
    magnet = re.findall(MAGNET_REGEX, url)
    return bool(magnet)

def new_thread(fn):
    """To use as decorator to make a function call threaded.
    Needs import
    from threading import Thread"""

    def wrapper(*args, **kwargs):
        thread = threading.Thread(target=fn, args=args, kwargs=kwargs)
        thread.start()
        return thread

    return wrapper


next_handler = CallbackQueryHandler(flip, pattern="nex", run_async=True)
previous_handler = CallbackQueryHandler(flip, pattern="pre", run_async=True)
dispatcher.add_handler(next_handler)
dispatcher.add_handler(previous_handler)
